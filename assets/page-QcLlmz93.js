import{j as e}from"./index-LtAfG_2p.js";import{C as t}from"./codeChunk-8Pie1Zmn.js";import{Z as s}from"./zoomImage-8qZONL8f.js";const r=[{title:"迴歸分析的意義",content:e.jsx(e.Fragment,{children:e.jsxs("ol",{children:[e.jsxs("li",{children:["相關與迴歸",e.jsxs("ul",{children:[e.jsx("li",{children:"相關是用來探討兩變項之間的關連程度，但分析中對兩個變項並不設計因果關係。"}),e.jsxs("li",{children:["在迴歸分析中，變項之間具有因果關係的意義，其中一定有一個變項被設定為",e.jsx("b",{children:"結果"}),"。"]})]})]}),e.jsxs("li",{children:["迴歸分析",e.jsxs("ul",{children:[e.jsx("li",{children:"當自變數只有一個時，為簡單迴歸分析，而超過一個自變項時，為多元迴歸分析（multiple regression，又稱複迴歸）。簡單迴歸分析是所有迴歸分析的基礎，可看做迴歸分析的原型。"}),e.jsx("li",{children:"基本上，迴歸分析的原型在自變項與應變項所用到的尺度皆是間距尺度（interval scale）或比例尺度（ratio scale）。"}),e.jsx("li",{children:"迴歸分析是以數學等式表示，研究者可根據數學等式去預測變項的變化。因此，在統計分析中，迴歸分析具有預測的作用。"})]})]}),e.jsxs("li",{children:["函數關係與統計關係",e.jsxs("ol",{type:"i",children:[e.jsxs("li",{children:["函數關係：是一種確定關係，表現在某一數值改變後，另一現象也隨之產生變化，而且有確定的值與之相對應。例如：",e.jsxs("ul",{children:[e.jsxs("li",{children:["求圓的面積：",e.jsx("center",{children:e.jsx("p",{children:e.jsxs("i",{children:["S=πr",e.jsx("sup",{children:"2"})]})})})]}),e.jsxs("li",{children:["加速度的公式：",e.jsx("center",{children:e.jsx("img",{src:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGMAAAAsCAYAAABxNQYsAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAASGSURBVHhe7ZpZKH1fFMeJB1KUiJIoklIypjwgw4tQygtlKDJkeECkpEh5MJUUTyQyZ4gHIsOTMTMllCEKmcdM319r/7bfX3/3uo7f717nOudTu85a95zT6X7PWWvttbcOZESDLIaIkMUQEbIYIkIWQ0TIYghgdnYWMTExiIyMRF5eHjY2NvgvwMHBAfLz89lvLS0t3CsMWQyBxMfHQ0dHhwnzf5qbm+Hr64uXlxfuEYYshkDoDycx+vr6uOc/AgMDsba2xi3haIUYX33T1MHi4iITo7y8nHt+09vbi5ycHG59DVGLMTw8DE9PT6SkpHAPUFRUBBcXF25pnru7O+jp6SE5OZl7gPv7e/j5+eH6+pp7vobov4zCwkJ4eXlxC9jb24OdnR23gPX1dYyMjODp6Yl71I+9vT38/f25BZSUlKCzs5NbX0f0YvT398PIyOhPqLq6ukJ6ejo7rq6uRk1NDba3txEeHs7e0I/o7u5GfX39h2N0dJSfrZzQ0FBYW1uz4/39fURERLDjv0X0YqyurrIYvbu7y2x6Cw8PD3F6egpbW1s8PDwwf3Z2NioqKtixMqKjo+Hj4/PhKCgo4GcrJzc3F7q6uri9vWXV1dsS9xV6LhJfCKIX4+bmhokxPz/PKhVKlERjYyMCAgLYMdHV1YWgoCBuqZeGhgb2TLW1tQrFoyRPlVVcXByOjo64VzWiF4PQ19dHR0cHKisruQeoqqpi4eKVgYEBODg4cEu9zMzMMDGcnJzY16EId3d3HB8fc+tzaIUYJiYmiI2NxfPzM/eAvZXBwcHc+p1bnJ2duaVeKG9RmFI01yBOTk7g5ubGrc+jFWJkZGS8S86Tk5Pw8PDgFlBXV8daEZqC2iHKoK84KyuLW59HK8RQhre395/EHhYWxvKKGKB5UVtbG6vyhKDVYuzs7LDqikrS1tZW7v1+qLKjZxKKVovx01ApBlUEY2NjODs7w8rKCqvxZdSDUjGociktLUVmZiY2NzdRVlYGAwODD7uSg4ODLFaqGkJLPqmgVAyKe4mJidwCi4FWVlbcUkxUVBSrcFSNubk5foXMWxSK0d7eDlNTU1xcXHAPWD+IVrk0AfWhqPH3E8bbuZEqFIrh6uqK1NRUboHd1MLCgrUBNEFxcTGb4f6EQSt/n+WdGMvLy+wmlLRfoRBFPmpffwT19M3MzFSOiYkJfoViaIJ3fn7+I4aQNY53YgwNDbE/nrqlxNLSEhISEmBpacn6MAsLC8yvCBJyampK5bi8vORXyLzlnRi0y8Hc3Jw14agxR91RWl2zsbFhFdXj4yM/U+ZfozBn0FdBCzev7QUqbZuamgQlIxnhKBRD5nuQvBgUdik0iwFJi0FhNykpia3MiQHJikFVHS3TGhoasqVcKkO/G8mKMT09zTYgUNU4Pj6udPlUk0g6TGmyq/AZJCvGa6eB9j2JBcmKQRNaR0dHbokDyYoREhKCtLQ0bokDSYpBXWhjY2P09PSIau1ckmJsbW2xfEFbM2lTg1iQbJii3et/u4X/XyNZMcSILIaIkMUQDcAv9rmZv2mSWwcAAAAASUVORK5CYII=",width:"99",heigh:"44",id:"12"})})]}),e.jsxs("li",{children:["以及常見之兩變量x與y之間的函數關係一般可以用下列數學關係表示：",e.jsx("center",{children:e.jsx("p",{children:e.jsx("i",{children:"y=f(x)"})})})]})]})]}),e.jsx("li",{children:"統計關係: 指現象之間存在的非確定性的數量依存關係。也就是說，雖然現象之間存在著數量的關係，當一變項的數值改變時，另一變項的數值也產生相應的變化，但這種關係並不是嚴格一對一對應的。"}),e.jsxs("ul",{children:[e.jsx("li",{children:"大多數的社會現象都有這種意涵。例如，教育程度與收入有關，但並不是所有教育程度高的人，收入就一定高。"}),e.jsxs("li",{children:["下式中的",e.jsx("i",{children:"ϵ"}),"為隨機誤差，反映隨機因素對y的影響。",e.jsx("center",{children:e.jsx("p",{children:e.jsx("i",{children:"y=f(x)+ϵ"})})})]}),e.jsxs("li",{children:["下圖顯示的就是兩變量之間的統計關係，雖然Y的變化隨著X的改變而增長，但不是所有的Y都在那條直線上，而是散佈在其周圍。",e.jsx(s,{className:"w-lg-50 w-sm-75 mx-auto",src:"/personal-website/assets/images/reg01.png"})]})]}),e.jsxs("li",{children:["線性關係",e.jsx("ol",{type:"i",children:e.jsxs("li",{children:["在線性關係中，用來表達自變項與應變項之間關係的方程式為：",e.jsx("center",{children:e.jsx("p",{children:e.jsx("i",{children:"Y=A+BX"})})}),e.jsxs("ul",{children:[e.jsx("li",{children:"其中，Y是應變項，X是自變項，A是截距或常數（intercept or constant），B是迴歸係數或稱斜率（regression coeﬃcient or slope）。"}),e.jsx("li",{children:"以下圖為例，截距為11.5，斜率為2.3，表示每增加1個單位的X，則y會增加2.3個單位。"}),e.jsx(t,{code:`
clear
set obs 50vations (_N) was 0, now 50
set seed 1245
gen x= int((100-1)*runiform() +1)

gen y= 11.5+2.3*x
*sc= scatter
twoway sc y x || lfit y x, ///
    legend(off) ///
    text(250 24 "y= 11.5+2.3*x") ///
    text(215 24 "when the rangr of {&epsilon} is 0") ///
    legend(off) ytitle("y")
graph save reg2-1.gph, replace

gen e1= (20-1)*runiform() +1
cap drop y
gen y= 11.5+2.3*x+e1
twoway sc y x || lfit y x, ///
    legend(off) ///
    text(285 24 "y= 11.5+2.3*x + {&epsilon}{sub:1}") ///
    text(250 24 "when the rangr of {&epsilon} is") ///
    text(215 24 "between 0-20") ///
    legend(off) ytitle("y")
*{&epsilon}{sub:1} 希臘字母 下標1
graph save reg2-2.gph, replace

gen e2= (100-1)*runiform() +1
cap drop y
gen y= 11.5+2.3*x+e2
twoway sc y x || lfit y x, ///
    legend(off) ///
    text(295 24 "y= 11.5+2.3*x + {&epsilon}{sub:1}") ///
    text(260 24 "when the rangr of {&epsilon} is") ///
    text(225 24 "between 0-100") ///
    legend(off) ytitle("y")
graph save reg2-3.gph, replace

gen e3= (200-1)*runiform() +1
cap drop y
gen y= 11.5+2.3*x+e3
twoway sc y x || lfit y x, ///
    legend(off) ///
    text(100 70 "y= 11.5+2.3*x + {&epsilon}{sub:1}") ///
    text(65  70 "when the rangr of {&epsilon} is") ///
    text(30  70 "between 0-200") ///
    legend(off) ytitle("y")
graph save reg2-4.gph, replace
graph export reg01.png, replace

graph combine reg2-1.gph reg2-2.gph reg2-3.gph reg2-4.gph, ycommon
graph export "reg02.png", replace`,lang:"stata"}),e.jsx(t,{code:`. clear

. set obs 50
number of observations (_N) was 0, now 50

. set seed 1245

. gen x= int((100-1)*runiform() +1)

. 
. gen y= 11.5+2.3*x

. *sc= scatter
. twoway sc y x || lfit y x, ///
>        legend(off) ///
>            text(250 24 "y= 11.5+2.3*x") ///
>            text(215 24 "when the rangr of {&epsilon} is 0") ///
>            legend(off) ytitle("y")

. graph save reg2-1.gph, replace
(file reg2-1.gph saved)

. 
. gen e1= (20-1)*runiform() +1

. cap drop y

. gen y= 11.5+2.3*x+e1

. twoway sc y x || lfit y x, ///
>        legend(off) ///
>            text(285 24 "y= 11.5+2.3*x + {&epsilon}{sub:1}") ///
>            text(250 24 "when the rangr of {&epsilon} is") ///
>            text(215 24 "between 0-20") ///
>            legend(off) ytitle("y")

. *{&epsilon}{sub:1} 希臘字母 下標1
. graph save reg2-2.gph, replace
(file reg2-2.gph saved)

. 
. gen e2= (100-1)*runiform() +1

. cap drop y

. gen y= 11.5+2.3*x+e2

. twoway sc y x || lfit y x, ///
>        legend(off) ///
>            text(295 24 "y= 11.5+2.3*x + {&epsilon}{sub:1}") ///
>            text(260 24 "when the rangr of {&epsilon} is") ///
>            text(225 24 "between 0-100") ///
>            legend(off) ytitle("y")

. graph save reg2-3.gph, replace
(file reg2-3.gph saved)

. 
. gen e3= (200-1)*runiform() +1

. cap drop y

. gen y= 11.5+2.3*x+e3

. twoway sc y x || lfit y x, ///
>        legend(off) ///
>            text(100 70 "y= 11.5+2.3*x + {&epsilon}{sub:1}") ///
>            text(65  70 "when the rangr of {&epsilon} is") ///
>            text(30  70 "between 0-200") ///
>            legend(off) ytitle("y")

. graph save reg2-4.gph, replace
(file reg2-4.gph saved)

. graph export reg01.png, replace
(file reg01.png written in PNG format)

. 
. graph combine reg2-1.gph reg2-2.gph reg2-3.gph reg2-4.gph, ycommon

. graph export "reg02.png", replace
(file reg02.png written in PNG format)`,lang:"output"}),e.jsx(s,{className:"w-lg-50 w-sm-75 mx-auto",src:"/personal-website/assets/images/reg02.png"})]})]})})]})]})]}),e.jsxs("li",{children:["線性迴歸模型",e.jsxs("ul",{children:[e.jsxs("li",{children:["在線性迴歸模型中，如上圖，雖然截距與斜率都一樣，但意義上卻相當不同。其不同點就在散佈于直線周遭的散佈點上，即在同一個X上的散佈點與直線上的點的距離上，即",e.jsx("i",{children:"ϵ"}),"上。此處的",e.jsx("i",{children:"ϵ"}),"代表隨機誤差。"]}),e.jsxs("li",{children:["換句話說，有些x值並不能夠準確地預測到所有的y值。這就說明了社會現象並非存在著一對一的對應關係。即因此故，正確的迴歸模型（regression model）應為：",e.jsx("center",{children:e.jsx("p",{children:e.jsx("i",{children:"Y=A+BX+ϵ"})})})]})]})]})]})})},{title:"STATA迴歸分析範例",content:e.jsxs(e.Fragment,{children:[e.jsx(t,{code:`clear
input x y
0  12
3  13
1  15
0  19
6  26
5  27
3  29
4  31
10 40
8  48
end

lab var x "先前犯罪紀錄"
lab var y "刑期(⽉)"

reg y x`,lang:"stata"}),e.jsx(t,{code:`. clear

. input x y

             x          y
  1. 0  12
  2. 3  13
  3. 1  15
  4. 0  19
  5. 6  26
  6. 5  27
  7. 3  29
  8. 4  31
  9. 10 40
 10. 8  48
 11. end

. lab var x "先前犯罪紀錄"

. lab var y "刑期(⽉)"

. 
. reg y x

      Source |       SS           df       MS      Number of obs   =        10
-------------+----------------------------------   F(1, 8)         =     20.57
       Model |         900         1         900   Prob > F        =    0.0019
    Residual |         350         8       43.75   R-squared       =    0.7200
-------------+----------------------------------   Adj R-squared   =    0.6850
       Total |        1250         9  138.888889   Root MSE        =    6.6144

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |          3   .6614378     4.54   0.002     1.474722    4.525278
       _cons |         14   3.372684     4.15   0.003     6.222576    21.77742
------------------------------------------------------------------------------`,lang:"output"}),e.jsx("p",{children:"此結果可分成兩部分，上面是有關模型的結果，下面則是迴歸係數的部分。"}),e.jsxs("ol",{children:[e.jsx("li",{children:"在上表中，Rseidual為殘差和，代表不能解釋的部分，平均殘差值為43.75。"}),e.jsx("li",{children:"Model SS會受到X與迴歸係數的影響，因此代表可以被解釋的部分，此處為900。"}),e.jsx("li",{children:"如何判斷一個模型的好壞："}),e.jsxs("ul",{children:[e.jsx("li",{children:"F ratio：代表可解釋部分與不可解釋之間的比值，比值愈高代表可被解釋的成分愈大。換言之，虛無假設為0的可能性愈低。"}),e.jsxs("li",{children:[e.jsxs("i",{children:["R",e.jsx("sup",{children:"2"})]}),"：是Model-ss/Total-ss之間的比值，其值域介於0與1之間。愈接近1，代表模型擬合程度愈高，即散佈點愈接近那條迴歸線。在本模型中，",e.jsxs("i",{children:["R",e.jsx("sup",{children:"2"})]}),"=0.72，是相當擬合的模型。"]}),e.jsxs("li",{children:["在只有一個自變項的情況下，X和Y之間相關係數的平方=",e.jsxs("i",{children:["R",e.jsx("sup",{children:"2"})]})]})]})]}),e.jsxs("div",{className:"my-2",children:[e.jsx("div",{className:"text-bold text-large",children:"迴歸係數的功用"}),e.jsxs("ol",{children:[e.jsx("li",{children:"首先，重點在斜率部分。以此處所得到的迴歸係數為例，3意味著每增加一次的犯罪紀錄，則刑期會多增加3個月。"}),e.jsxs("li",{children:["可用來推算出迴歸線的各個點（即，迴歸預測值，用",e.jsx("i",{children:"Ŷ"}),"表示），從而畫出迴歸線。",e.jsx(t,{code:`cap drop yhat
predict yhat, xb
list x y yhat, nolab clean noobs
twoway (sca y x, mc(black)) ///
       (sca yhat x, c(l) mc(red)), ///
       ylab(0(5)50, angle(0)) ///
       ytitle("刑期（月）") ///
       legend(label(1 "x的原始觀察點") label(2 "y的預測點"))
graph export reg03.png, replace`,lang:"stata"}),e.jsx(t,{code:`. cap drop yhat

. predict yhat, xb

. list x y yhat, nolab clean noobs

     x    y   yhat  
     0   12     14  
     3   13     23  
     1   15     17  
     0   19     14  
     6   26     32  
     5   27     29  
     3   29     23  
     4   31     26  
    10   40     44  
     8   48     38  

. twoway (sca y x, mc(black)) ///
>            (sca yhat x, c(l) mc(red)), ///
>        ylab(0(5)50, angle(0)) ///
>        ytitle("刑期（月）") ///
>        legend(label(1 "x的原始觀察點") label(2 "y的預測點"))

. graph export reg03.png, replace
(file reg03.png written in PNG format)`,lang:"output"}),e.jsx(s,{className:"w-lg-50 w-sm-75 mx-auto",src:"/personal-website/assets/images/reg03.png"})]}),e.jsx("li",{children:"得到的迴歸係數可用來估算當x在某一狀況時，Y可能有的結果。"}),e.jsxs("li",{children:["其次，我們可以從迴歸係數故估算殘差值，從而了解模型的擬合程度（The goodness of ﬁt）。此部分可以用來了解模型的優劣。",e.jsx(t,{code:`predict cancha, resid
list x y yhat cancha, nolab clean noobs`,lang:"stata"}),e.jsx(t,{code:`. predict cancha, resid

. list x y yhat cancha, nolab clean noobs

     x    y   yhat   cancha  
     0   12     14       -2  
     3   13     23      -10  
     1   15     17       -2  
     0   19     14        5  
     6   26     32       -6  
     5   27     29       -2  
     3   29     23        6  
     4   31     26        5  
    10   40     44       -4  
     8   48     38       10`,lang:"output"})]}),e.jsxs("li",{children:["一個好的迴歸模型其殘差與X變項之間的關係為0，例如：",e.jsx(t,{code:"corr x cancha",lang:"stata"}),e.jsx(t,{code:`. corr x cancha
(obs=10)

             |        x   cancha
-------------+------------------
           x |   1.0000
      cancha |   0.0000   1.0000`,lang:"output"})]}),e.jsxs("li",{children:["殘差與y的預測值之間的相關係數也應該是0，例如：",e.jsx(t,{code:"corr yhat cancha",lang:"stata"}),e.jsx(t,{code:`. corr yhat cancha 
(obs=10)

             |     yhat   cancha
-------------+------------------
        yhat |   1.0000
      cancha |   0.0000   1.0000`,lang:"output"})]})]})]})]})},{title:"矩陣運算與迴歸",content:e.jsxs(e.Fragment,{children:[e.jsxs("div",{className:"my-2",children:[e.jsx("div",{className:"text-bold text-large",children:"矩陣解聯立方程式"}),e.jsx("p",{children:"6x+3y+7z=51"}),e.jsx("p",{children:"1x+4y+0z=26"}),e.jsx("p",{children:"5x+2y+8z=46"}),e.jsx("p",{children:"輸入資料："}),e.jsx(t,{code:`clear matrix
mat a = [6,3,7\\1,4,0\\5,2,8]  /*mat: matrix的縮寫，輸入矩陣a*/
mat list a    /*列出矩陣a*/
mat b = [51\\26\\46]
mat list b`,lang:"stata"}),e.jsx(t,{code:`. clear matrix

. mat a = [6,3,7\\1,4,0\\5,2,8]  /*mat: matrix的縮寫，輸入矩陣a*/

. mat list a    /*列出矩陣a*/

a[3,3]
    c1  c2  c3
r1   6   3   7
r2   1   4   0
r3   5   2   8

. mat b = [51\\26\\46]

. mat list b

b[3,1]
    c1
r1  51
r2  26
r3  46`,lang:"output"}),e.jsxs("p",{children:["求解公式：r =(a",e.jsx("sup",{children:"-1"}),")*b"]}),e.jsx(t,{code:`mat inva=inv(a)
mat r=inva*b
mat list r`,lang:"stata"}),e.jsx(t,{code:`. mat inva=inv(a)

. mat r=inva*b

. mat list r

r[3,1]
    c1
c1   2
c2   6
c3   3`,lang:"output"}),e.jsx("p",{children:"Ans：x=2, y=6, z=3"})]}),e.jsxs("div",{className:"my-2",children:[e.jsx("div",{className:"text-bold text-large",children:"矩陣與迴歸係數的運算"}),e.jsx("p",{children:"輸入資料："}),e.jsx(t,{code:`clear
input y x1 x2 x3 
 .6  8 12 5
1.2 11  6 2
1.0  9  6 1
 .7  6  3 3
 .3  6 18 4
end`,lang:"stata"}),e.jsx(t,{code:`. clear

. input y x1 x2 x3 

             y         x1         x2         x3
  1.  .6  8 12 5
  2. 1.2 11  6 2
  3. 1.0  9  6 1
  4.  .7  6  3 3
  5.  .3  6 18 4
  6. end`,lang:"output"}),e.jsx("p",{children:"建立變項數與樣本數"}),e.jsx(t,{code:`clear matrix
d
sca k = r(k)
sca n=r(N)`,lang:"stata"}),e.jsx(t,{code:`. clear matrix

. d

Contains data
  obs:             5                          
 vars:             4                          
 size:            80                          
---------------------------------------------------------------------------------------------------------------
              storage   display    value
variable name   type    format     label      variable label
---------------------------------------------------------------------------------------------------------------
y               float   %9.0g                 
x1              float   %9.0g                 
x2              float   %9.0g                 
x3              float   %9.0g                 
---------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.

. sca k = r(k)

. sca n=r(N)`,lang:"output"}),e.jsx("p",{children:"輸入矩陣y"}),e.jsx(t,{code:`mat y =(.6\\1.2\\1.0\\.7\\.3)
mat list y, title(Y變項的矩陣)`,lang:"stata"}),e.jsx(t,{code:`. mat y =(.6\\1.2\\1.0\\.7\\.3)

. mat list y, title(Y變項的矩陣)

y[5,1]:  Y變項的矩陣
     c1
r1   .6
r2  1.2
r3    1
r4   .7
r5   .3`,lang:"output"}),e.jsx("p",{children:"輸入矩陣 X1, X2, and X3。"}),e.jsx("p",{children:"迴歸計算的是自變項每增加1單位，應變項的變化量，因此矩陣每一行的第一個數字都是1。"}),e.jsx(t,{code:`matrix x =(1,8,12,5\\1,11,6,2\\1,9,6,1\\1,6,3,3\\1,6,18,4)

/* 產生 x'，即x的轉置矩陣(transpose matrix) */ 
matrix xp=x'
mat list xp, title(轉置矩陣 x')  

/* 產生 x'x，意即成為下三角矩陣(triangular matrix)，右上空白位置對應左下數值  */ 
matrix xpx=xp*x             
matrix list xpx, title(產生下三角矩陣 x'x)  

/* 產生 x'y  */     
matrix xpy=xp*y
matrix list xpy

/* 產生 x'x的反矩陣，意即 (x'x)^-1 */
matrix invxp= inv(xpx)
matrix list invxp, title(x'x的反矩陣) `,lang:"stata"}),e.jsx(t,{code:`. matrix x =(1,8,12,5\\1,11,6,2\\1,9,6,1\\1,6,3,3\\1,6,18,4)

. 
. /* 產生 x'，即x的轉置矩陣(transpose matrix) */ 
. matrix xp=x'

. mat list xp, title(轉置矩陣 x')  

xp[4,5]:  轉置矩陣 x'
    r1  r2  r3  r4  r5
c1   1   1   1   1   1
c2   8  11   9   6   6
c3  12   6   6   3  18
c4   5   2   1   3   4

. 
. /* 產生 x'x，意即成為下三角矩陣(triangular matrix)，右上空白位置對應左下數值  */ 
. matrix xpx=xp*x             

. matrix list xpx, title(產生下三角矩陣 x'x)  

symmetric xpx[4,4]:  產生下三角矩陣 x'x
     c1   c2   c3   c4
c1    5
c2   40  338
c3   45  342  549
c4   15  113  159   55

. 
. /* 產生 x'y  */     
. matrix xpy=xp*y         

. matrix list xpy  

xpy[4,1]
      c1
c1   3.8
c2    33
c3  27.9
c4   9.7

. 
. /* 產生 x'x的反矩陣，意即 (x'x)^-1 */
. matrix invxp= inv(xpx)           

. matrix list invxp, title(x'x的反矩陣) 

symmetric invxp[4,4]:  x'x的反矩陣
            c1          c2          c3          c4
c1   8.9730892
c2  -.77388535   .07643312
c3  -.03158174   .00106157   .01158882
c4  -.76592357   .05095541  -.02707006   .20063694`,lang:"output"}),e.jsx("p",{children:"計算出迴歸係數"}),e.jsx(t,{code:`matrix regbx=invxp*xpy  
matrix list regbx, title(迴歸係數)`,lang:"stata"}),e.jsx(t,{code:`. matrix regbx=invxp*xpy  

. matrix list regbx, title(迴歸係數)

regbx[4,1]:  迴歸係數
            c1
c1   .24893312
c2   .10541401
c3  -.02423036
c4  -.03805732`,lang:"output"}),e.jsx("p",{children:"迴歸係數的變異數"}),e.jsx(t,{code:`mat e = y-x*regbx   /* e=y-xp，意即迴歸的殘差 */
mat ep=e'
mat _sb=((ep*e)/(n-k))*inv(xpx) 
mat list _sb, title(迴歸係數的變異數)`,lang:"stata"}),e.jsx(t,{code:`. mat e = y-x*regbx   /* e=y-xp，意即迴歸的殘差 */

. mat ep=e'

. mat _sb=((ep*e)/(n-k))*inv(xpx) 

. mat list _sb, title(迴歸係數的變異數)

symmetric _sb[4,4]:  迴歸係數的變異數
            c1          c2          c3          c4
c1    .0051581
c2  -.00044486   .00004394
c3  -.00001815   6.102e-07   6.662e-06
c4  -.00044028   .00002929  -.00001556   .00011533`,lang:"output"}),e.jsx("p",{children:"迴歸係數的標準誤"}),e.jsx(t,{code:`/* 將上面矩陣中轉換成為對角線矩陣，意即保留對角線的數值，但將其它數值轉為0。*/
mat S = diag(vecdiag(_sb))  
mat S = cholesky(S)   /*開根號*/
mat li S, title(迴歸係數的標準誤)

/*將上面矩陣中對角線上的標準誤轉置成為行矩陣（Column Matrix ）*/
mat ste = vecdiag(S)'
mat li ste`,lang:"stata"}),e.jsx(t,{code:`. /* 將上面矩陣中轉換成為對角線矩陣，意即保留對角線的數值，但將其它數值轉為0。*/
. mat S = diag(vecdiag(_sb))  

. mat S = cholesky(S)   /*開根號*/

. mat li S, title(迴歸係數的標準誤)

symmetric S[4,4]:  迴歸係數的標準誤
           c1         c2         c3         c4
c1   .0718199
c2          0  .00662849
c3          0          0  .00258103
c4          0          0          0  .01073938

. 
. /*將上面矩陣中對角線上的標準誤轉置成為行矩陣（Column Matrix ）*/
. mat ste = vecdiag(S)'

. mat li ste

ste[4,1]
           r1
c1   .0718199
c2  .00662849
c3  .00258103
c4  .01073938`,lang:"output"}),e.jsx("p",{children:"與迴歸結果對照"}),e.jsx(t,{code:"reg y x1 x2 x3",lang:"stata"}),e.jsx(t,{code:`. reg y x1 x2 x3

      Source |       SS           df       MS      Number of obs   =         5
-------------+----------------------------------   F(3, 1)         =    284.96
       Model |  .491425183         3  .163808394   Prob > F        =    0.0435
    Residual |  .000574842         1  .000574842   R-squared       =    0.9988
-------------+----------------------------------   Adj R-squared   =    0.9953
       Total |  .492000025         4  .123000006   Root MSE        =    .02398

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |    .105414   .0066285    15.90   0.040      .021191     .189637
          x2 |  -.0242304    .002581    -9.39   0.068    -.0570255    .0085648
          x3 |  -.0380573   .0107394    -3.54   0.175    -.1745142    .0983995
       _cons |    .248933   .0718199     3.47   0.179    -.6636259    1.161492
------------------------------------------------------------------------------`,lang:"output"})]})]})}];export{r as default};
